---
title: 'Application of Machine Learning Algorithms to Cancer Diagnosis'
author: "Steve and Jonathan"
date: " `r as.Date(Sys.time())` "
output: 
  html_document: 
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
---




```{r setup, include=FALSE, cache=F}
knitr::opts_chunk$set(echo = F, warning = F, message = F, fig.width = 10, fig.height = 10, results = "asis")
options(width = 10)
rm(list=ls())
# Set practice root directory
basedir <- "C:/Users/sbicko/Google Drive/PHD/Practical Exercises/Wisconsin Cancer Dataset/"

knitr::opts_knit$set(root.dir = normalizePath(basedir))
```

# Introduction

Machine Learning (ML) is a science which involves the application of Artificial Intelligence (AI) that enables the computers to automatically learn and improve or get things done based on experience without being explicitly programed. This involves computer looking for patterns based on previous observations, experiences or instructions. In this exercise, we apply some of the Machine Learning Algorithms in Diagnosis of Cancer using [Breast Cancer Wisconsin Data Set](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)) and also review some of the papers that have been published analyzing the same data set.


## Wisconsin Diagnostic Breast Cancer (WDBC)

Various ML algorithms, such as Artificial neural networks (ANNs) and decision trees (DTs) have been used in cancer detection and diagnosis. Using [Breast Cancer (WDBC) data set](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names), we'll implement these algorithms in analyzing WDBC data set.

The data set contains $569$ cases with $32$ variables. The diagnosis classification is either (M = Malignant) or (B = Benign). Other variables include cell nucleus:

* Radius
* Texture
* Perimeter
* Smoothness
* Compactness
* Concave points
* Symmetry
* Fractal dimension



```{r usefulpackages, echo=T}
# Useful Packages

pkgs <- c("data.table", "Amelia", "stringr", "dplyr", "corrplot", "caret", "MASS", "openxlsx",
          "ROCR", "caTools")
if (!"pacman" %in% installed.packages()[,1]){
  install.packages("pacman")
}
pacman::p_load(pkgs, install = T, character.only = T)
```



```{r usefulfunctions, echo=T}
# Functions to be used

factorFunc <- function(x){
  factor(x)
}



# Variables with missing Values
missPropFunc <- function(dat){
  dat <- as.data.frame(dat)
  vars <- apply(dat,2,function(x) round((sum(is.na(x))/length(x))*100, 2))
  miss_vars <- vars[vars>0]
  miss_data <- as.data.frame(miss_vars)
  if (nrow(miss_data)>0){
    return(miss_data)
  } else {
    print("No missing entries")
  }
}

```



We download the data set and description file from the [site](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data), convert them to \textit{.xlsx} files and then store locally. Illustrated below.

```{r wdbc_df, echo=T}
# Check if Dataset dir exist otherwise R create it.
if(!exists("Datasets")){
  dir.create(file.path(basedir, "Datasets"))
  dir.create(file.path("Datasets", "Out"))
  dir.create(file.path("Datasets", "In"))
  cat("Dataset will be saved in created directory \n", 
      paste(basedir, "Dataset/Out"))
}


# Define data url
df_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
desc_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names"

# Check if the dataset already exist
pattern <- "wdbc_data" # How is the dataset named in the computer?
df_path <- paste(basedir, "Datasets/Out/", sep = '')
if(length(list.files(df_path)>0)){
  if (grepl(pattern, list.files(df_path), ignore.case = T)){
  df_name <- grep(pattern, list.files(df_path), value = T)
  print("Reading dataset from your computer... \n")
  working_df <- read.xlsx(paste("Datasets/Out/", df_name, sep = ''), sheet = 2)
  cat(df_name, " dataset already saved!!! We'll proceed to modeling.", "\n")
  }
} else {
  
  # Download data
  cat("Dowloading dataset from ", df_url, "\n")
  wdbc_df <- fread(df_url, showProgress=F)
  # Get variable information
  desc_file <- readLines(desc_url)
  var_info_pos <- grep(". Attribute information", desc_file, ignore.case = T)+2
  var_info <- desc_file[var_info_pos:(var_info_pos+5+ncol(wdbc_df)/3)]
  var_info <- var_info[!var_info %in% c("", "Ten real-valued features are computed for each cell nucleus:", "3-32)")]
  var_info <- sub('.*\\\t', '', var_info)
  var_info <- sub('.*\\) \\b', '', var_info)
  var_info_df <- data.frame(vars=var_info)
  var_info_df$labels <- as.character(var_info_df$vars)
  var_info_df$vars <- str_wrap(tolower(sub('\\(.*', '', var_info_df$vars)))
  var_info_df$vars <- sub(" ", "_", var_info_df$vars)
  rep_vars <- var_info_df[3:nrow(var_info_df), ]
  var_info_df <- rbind(var_info_df, rep_vars[rep(seq_len(nrow(rep_vars)), 2), ])
  measurements <- rep(c("mean", "se", "worst"), each=10)
  var_info_df$vars[3:nrow(var_info_df)] <- paste(var_info_df$vars[3:nrow(var_info_df)], measurements, sep = '_')
  measurements <- rep(c("Mean", "Standard error", "Worst"), each=10)
  var_info_df$labels[3:nrow(var_info_df)] <- paste(var_info_df$labels[3:nrow(var_info_df)], measurements, sep = ' - ')
  colnames(wdbc_df) <- var_info_df$vars
  #Add variable names to the data set and save the data set in .xlsx together the variable discription
  wdbc_df_info <- list(Description = var_info_df, wdbc_data = wdbc_df)
  openxlsx::write.xlsx(wdbc_df_info, "Datasets/Out/wdbc_dataset.xlsx") # Uncomment to save the dataset
  working_df <- wdbc_df
  cat(pattern, " didn't exist!!! We've downloaded data from the url ", df_url, "\n Dataset dim: ",
      dim(wdbc_df))

}


```



### Data cleaning and Descriptives

```{r desc, echo=T}
str(working_df)
```

Convert \textbf{diagnosis} to factor and check for missingness.

```{r factor, echo=T}
working_df$diagnosis <- factorFunc(working_df$diagnosis)
missPropFunc(working_df)
```

Summarize numerical variables.

```{r, echo=T}

vars_type <- sapply(working_df, class, simplify = F)
num_vars <- names(grep("numer", vars_type, value = T))
summary_tab <- lapply(working_df[, num_vars], summary)
summary_df <- Reduce(rbind, summary_tab)
summary_df <- apply(summary_df,2, function(x){round(x, 3)})
row.names(summary_df) <- names(summary_tab)
knitr::kable(summary_df)
```


The overall distribution of diagnosis indicators and distribution accross all features:

```{r, echo=T}
knitr::kable(working_df %>% 
  count(diagnosis) %>% 
  mutate(percentage=round(n/sum(n)*100, 2)))
```



```{r, echo=T}
ind_vars <- names(working_df)[!names(working_df) %in% c("diagnosis", "id_number")]
form <- as.formula(paste(ind_vars[1], "~", "diagnosis"))
old.par <- par(mfrow=c(5, 6))
for (i in 1:length(ind_vars)){
 boxplot(form, data = working_df, main=paste("Cancer diagnosis by", ind_vars[i]), xlab="Diagnosis", cex.main=0.8, ylab=ind_vars[i], cex=0.8) 
}
par(old.par)
```


#### Correlation

The next step invloves checking the correlation between the features. This will help us reduce the number of features based on the strength of association. In addition, training a model on a data set with features which have little or no correlation may lead to inaccurate results. It is therefore important to identify and filter out features which are not correlated to other features, more so if measuring the similar aspects, [Yu, Lei and Liu, Huan](http://www.aaai.org/Papers/ICML/2003/ICML03-111.pdf).


```{r, echo=T}
features_df <- working_df[, ind_vars]
cor_mat <- cor(features_df)
corrplot(cor_mat, order = "hclust", tl.cex = 1, addrect = 8)
```


## Model Fitting


### Principal Component Analysis and Linear Discriminant Analysis

Since there are many correlated features, we will use PCA to reduce the dimension of the data. Both LDA and PCA are used to classify and reduce the dimentionality of the data. One of the key difference is that PCA is unsupervised learning while LDA is supervised. 


#### PCA


```{r, echo=T}
pca_result <- prcomp(working_df[, ind_vars], center = TRUE, scale = TRUE)
biplot(pca_result, scale = 0)
```


To access the number of components which would explain much of the variations, we use a scree plot.

```{r, echo=T}
# Compute the variance of each componet
pca_var <- (pca_result$sdev)^2
# Proportion of variance explained
prop_var_exp <- pca_var/sum(pca_var)
round(prop_var_exp, 3)*100
```

The result above shows that the first component explans more than $44\%$ variance. Second component explains $19\%$ variance and so on. The scree plot would help to select the number of componets for modelling.

```{r, echo=T}
plot(prop_var_exp, xlab = "Principal Component",
             ylab = "Proportion of Variance Explained",
             type = "b")
```

The plot above shows that approximately $10$ componets explains around `r round(sum(prop_var_exp[1:10])*100, 3)`% of the variance while $17$ components explains more than `r round(sum(prop_var_exp[1:17])*100, 3)`% of the variance. The comulative variance plot below shows a clear picture of the components.


```{r, echo=T}
plot(cumsum(prop_var_exp), xlab = "Principal Component",
             ylab = "Cumulative Proportion of Variance Explained",
             type = "b")
```


We can view the distribution of the diagnosis between the two diagnosis outcomes.

```{r}
pca_df <- pca_result$x %>% data.frame()
str(pca_df)
```


```{r}
p <- ggplot(pca_df, aes(x=PC1, y=PC2, col=working_df$diagnosis)) + geom_point(alpha=0.5) +
  labs(color = "Diagnosis")
p
```



#### LDA

```{r, echo=T}
lda_result <- lda(diagnosis~., data = working_df, 
                  center=T, scale = T)
lda_result$prior
```

The lda result contains the prior probability of each diagnosis class, counts, class-specific means, singular values (svd) and so on. We can use svd to compute the amount of between-group variance that is explained by each linear discriminant.

```{r, echo=T}
prop_var <- lda_result$svd^2/sum(lda_result$svd^2)
prop_var
```

We see that the first linear discriminant explains more than `r prop_var*100`% of the between-group variance in the data.


```{r, echo=T}
lda_result_df <- predict(lda_result, working_df)
lda_result_df <- lda_result_df$x %>% as.data.frame()
lda_result_df <- cbind(lda_result_df, 
                       diagnosis=working_df[, "diagnosis"])
p <- ggplot(lda_result_df, aes(x=LD1, fill=diagnosis)) + geom_density(alpha=0.5) + 
  labs(color = "Diagnosis")
p
```



### Machine Learning Models

This section will apply various ML algorithms using both PCA and LDA methods. We first start by creating trainig and testing datasets.


```{r, echo=T}
set.seed(2000)
df_index <- createDataPartition(working_df$diagnosis, p=0.7, list = F)
train_df <- working_df[df_index, -1]
test_df <- working_df[-df_index, -1]
```


Data \textbf{pre-processing} involves transforming data into a specific format to improve the performance of machine learning algorithms. We'll use \textbf{preProcess} function in package \textit{caret} to transform the data.

Our main focus is transforming our predictors (characteristics) such that we reduce their dimensionality to fewer dimension where the new characterisitcs are uncorrelated. Therefore, we'll apply \textit{pca} method with a threshold of $.99$.


```{r, echo=T}
model_control <- trainControl(method="cv",
                            number = 5,
                            preProcOptions = list(thresh = 0.99),
                            classProbs = TRUE,
                            summaryFunction = twoClassSummary)
```


#### LDA

Define training and testing data sets for LDA models.


```{r, echo=T}
train_lda_df <- lda_result_df[df_index,]
test_lda_df <- lda_result_df[-df_index,]
```


```{r, echo=T}
lda_model <- train(diagnosis~., train_lda_df,  method="lda2",  metric="ROC",
                   preProc = c("center", "scale"), trControl=model_control)
```




Using \textit{predict} function, we generate the clasiffication and posterior probabilities based on the LDA model.

```{r, echo=T}
lda_predicted <- predict(lda_model, test_lda_df)
knitr::kable(as.data.frame(table(lda_predicted)))
```

We can summarize the performance of the LDA classification  using \textit{Confusion Matrix}.

```{r, echo=T}
lda_confusion_mat <- confusionMatrix(lda_predicted, test_lda_df$diagnosis, positive = "M")
knitr::kable(lda_confusion_mat$table)
```


Overall accuracy

```{r}
knitr::kable(data.frame(lda_confusion_mat$overall))
```



Confusion Matrix statistics

```{r}
knitr::kable(data.frame(lda_confusion_mat$byClass))
```




The overall accuracy of our model is `r round(lda_confusion_mat$overall[1], 4)*100`%. In addition, our classifier correctly identified \textit{M} `r round(lda_confusion_mat$byClass[1], 4)*100`% of the time (correctly predicting \textit{M} when indeed we should). Further, the true negatives (our specificity) is `r round(lda_confusion_mat$byClass[2], 4)*100`%.


```{r}
lda_predicted_prob <- predict(lda_model, test_lda_df, type="prob")
# colAUC(lda_predicted_prob, test_lda_df$diagnosis, plotROC=TRUE)
```



```{r}
  ROCRpred <- prediction(lda_predicted_prob$M, test_lda_df$diagnosis)
  ROCRperf <- performance(ROCRpred, 'tpr','fpr')
  auc <- performance(ROCRpred, measure = "auc")
  auc <- auc@y.values[[1]]
  plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7), main="ROC Curve")
  lines(x=c(0, 1), y=c(0, 1), col="black", lwd=1)
  legend("bottomright", c(paste("ROC curve (AUC = ", round(auc, 3), ")", sep = ''), "AUC = 0.5"),
         col=c("red", "black"), lwd=c(1,1))

```

